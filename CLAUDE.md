# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Spring Boot 4.0.0 application for learning Apache Kafka Streams with **Confluent Schema Registry** and **Avro** serialization. Uses Java 21 and Maven.

## Build Commands

```bash
./mvnw clean install          # Build (generates Avro classes)
./mvnw spring-boot:run        # Run
./mvnw test                   # Test
./mvnw avro:schema            # Generate Avro classes only
```

## Docker Commands

```bash
docker-compose up -d                    # Start Kafka + Schema Registry
docker-compose down                     # Stop all
docker-compose logs -f schema-registry  # View Schema Registry logs
```

## Project Structure

```
src/main/
├── avro/
│   └── employee.avsc                    # Avro schema definitions
├── java/com/github/kafka_streams/
│   ├── KafkaStreamsApplication.java     # Entry point
│   ├── avro/
│   │   └── Employee.java                # Generated by Avro plugin (DO NOT EDIT)
│   ├── config/
│   │   └── KafkaStreamsConfig.java      # Stream topologies
│   └── controller/
│       └── MessageController.java       # REST endpoint for testing
└── resources/
    └── application.yaml                 # Kafka & Schema Registry config
```

## Kafka Topics

| Topic | Key | Value | Purpose |
|-------|-----|-------|---------|
| input-topic | String | String | Basic string input |
| output-topic | String | String | Basic string output |
| filtered-topic | String | String | Filtered strings (length > 5) |
| employee-topic | String | Employee (Avro) | Employee input |
| engineering-employees | String | Employee (Avro) | Filtered Engineering dept |
| employee-with-bonus | String | Employee (Avro) | Employees with 10% salary bonus |
| employee-by-dept | Department | Employee (Avro) | Re-keyed by department |

## Key Technologies

### Confluent Stack (v7.7.0)
- **Schema Registry** - Centralized schema management at localhost:8081
- **Avro Serde** - `SpecificAvroSerde` for type-safe serialization
- **Auto Schema Registration** - Schemas auto-registered on first produce

### Avro Schema Generation
- Schemas defined in `src/main/avro/*.avsc`
- Java classes generated to `src/main/java` by `avro-maven-plugin`
- Generated classes use builder pattern: `Employee.newBuilder().setName("x").build()`

### Serde Configuration
```java
Serde<Employee> serde = new SpecificAvroSerde<>();
serde.configure(Map.of("schema.registry.url", "http://localhost:8081"), false);
// false = value serde (registers as "topic-value")
// true = key serde (registers as "topic-key")
```

## Services (docker-compose.yml)

| Service | Port | Purpose |
|---------|------|---------|
| Zookeeper | 2181 | Kafka coordination |
| Kafka | 9092 | Message broker |
| Schema Registry | 8081 | Schema storage & validation |
| Kafka UI | 8080 | Web UI for Kafka/Schema Registry |

## Learning Progress

Completed:
- Phase 1: Foundations (setup, config, basic topology, serdes)
- Phase 2.1: Filter
- Phase 2.2: Map/MapValues
- Schema Registry integration with Avro

Next:
- Phase 2.3: FlatMap
- Phase 2.4: Branch
- Phase 2.5: Merge
- Phase 3: Stateful Operations (GroupBy, Aggregate, KTable, Joins)
- Phase 4: Windowing
- Phase 5: State Stores & Interactive Queries
- Phase 6: Error Handling & Production
- Phase 7: Advanced (Processor API, Testing)

## Useful Commands

```bash
# Check Schema Registry subjects
curl http://localhost:8081/subjects

# Get schema for a subject
curl http://localhost:8081/subjects/employee-topic-value/versions/latest

# Produce Avro message (requires avro-tools)
# Or use the REST controller: POST /api/messages
```
